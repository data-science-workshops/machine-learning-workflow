{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz laden\n",
    "\n",
    "Quelle: [https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/safe-driver-prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadaten extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for column in df.columns:\n",
    "    # Defining the role\n",
    "    if column == 'target':\n",
    "        role = 'target'\n",
    "    elif column == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in column or column == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in column or column == 'id':\n",
    "        level = 'nominal'\n",
    "    elif df[column].dtype == np.dtype('float64'):\n",
    "        level = 'interval'\n",
    "    elif df[column].dtype == np.dtype('int64'):\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if column == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = df[column].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    column_dict = {\n",
    "        'column_name': column,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(column_dict)\n",
    "    \n",
    "df_meta = pd.DataFrame(data, columns=['column_name', 'role', 'level', 'keep', 'dtype'])\n",
    "df_meta.set_index('column_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion # , Pipeline\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, Normalizer, StandardScaler, LabelBinarizer, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cols():\n",
    "    query = df_meta[(df_meta.level == 'binary') & (df_meta.keep) & (df_meta.index != 'target')].index\n",
    "    return df[query].columns.values\n",
    "\n",
    "def nominal_cols():\n",
    "    query = df_meta[(df_meta.level == 'nominal') & (df_meta.keep) & (df_meta.index != 'id')].index\n",
    "    return df[query].columns.values\n",
    "\n",
    "def interval_cols():\n",
    "    query = df_meta[(df_meta.level == 'interval') & (df_meta.keep)].index\n",
    "    return df[query].columns.values\n",
    "\n",
    "def ordinal_cols():\n",
    "    query = df_meta[(df_meta.level == 'ordinal') & (df_meta.keep)].index\n",
    "    return df[query].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('union',  FeatureUnion([\n",
    "        ('binary', Pipeline([\n",
    "            ('impute', DataFrameMapper([\n",
    "                (binary_cols(), Imputer(missing_values=-1, strategy='most_frequent', axis=0))\n",
    "            ], input_df=True))\n",
    "        ])),\n",
    "\n",
    "        ('nominal', Pipeline([\n",
    "            ('label_binarize', DataFrameMapper(\n",
    "                [(c, LabelBinarizer()) for c in nominal_cols()] \n",
    "            , input_df=True))\n",
    "        ])),\n",
    "\n",
    "        ('interval', Pipeline([\n",
    "            ('impute', DataFrameMapper([\n",
    "                (interval_cols(), Imputer(missing_values=-1, strategy='mean', axis=0))\n",
    "            ], input_df=True)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])),\n",
    "\n",
    "        ('ordinal', Pipeline([\n",
    "            ('impute', DataFrameMapper([\n",
    "                (ordinal_cols(), Imputer(missing_values=-1, strategy='most_frequent', axis=0))\n",
    "            ], input_df=True)),\n",
    "            ('scaler', MinMaxScaler(feature_range=(0, 1)))\n",
    "        ])),\n",
    "    ])),\n",
    "    ('classify', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_apriori = 0.30\n",
    "\n",
    "nb_0 = len(df.loc[df.target == 0].index)\n",
    "nb_1 = len(df.loc[df.target == 1].index)\n",
    "\n",
    "undersampling_rate = ((1 - desired_apriori) * nb_1) / (nb_0 * desired_apriori)\n",
    "undersampled_nb_0 = int(undersampling_rate * nb_0)\n",
    "\n",
    "df_X = df.drop('target', axis=1)\n",
    "df_y = df['target']\n",
    "\n",
    "cc = RandomUnderSampler(ratio={0: undersampled_nb_0})\n",
    "X_cc, y_cc = cc.fit_sample(df_X, df_y.ravel())\n",
    "\n",
    "df_X = pd.DataFrame(X_cc, columns=df_X.columns)\n",
    "df_y = pd.DataFrame(y_cc, columns=['target'])\n",
    "\n",
    "df = df_X.join(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suche nach den besten Parametern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'classify': [DecisionTreeClassifier(criterion='gini', class_weight=None)],\n",
    "        'classify__criterion': ['gini', 'entropy'],\n",
    "        'classify__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        'classify': [RandomForestClassifier(n_estimators=10, criterion='gini', class_weight=None, n_jobs=-1)],\n",
    "        'classify__n_estimators': [10, 50, 100],\n",
    "        'classify__criterion': ['gini', 'entropy'],\n",
    "        'classify__class_weight': [None, 'balanced'],\n",
    "        'classify__warm_start': [False, True]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search ausf√ºhren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "scoring = { # weighted, binary, None\n",
    "    'precision_score': make_scorer(precision_score, average='binary'),\n",
    "    'recall_score': make_scorer(recall_score, average='binary'),\n",
    "    'f1_score': make_scorer(f1_score, average='binary'),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "refit_score = 'f1_score'\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=skf, param_grid=param_grid, scoring=scoring, refit=refit_score,\n",
    "                    return_train_score=True, n_jobs=-1)\n",
    "grid.fit(df_X, df_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Liste der Scoring-Parameter](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = cross_val_predict(grid.best_estimator_, df_X, df_y, cv=StratifiedKFold(2), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, df_y, target_names=['target = 0', 'target = 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit f1_score\n",
    "\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#  target = 0       0.71      0.71      0.71     49952\n",
    "#  target = 1       0.34      0.33      0.34     22361\n",
    "\n",
    "# avg / total       0.59      0.60      0.60     72313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as pickle\n",
    "\n",
    "model_pkl_path = 'model.pkl'\n",
    "\n",
    "with open(model_pkl_path, 'wb') as fh:\n",
    "    pickle.dump(grid.best_estimator_, fh)\n",
    "    print('Pickled model to \"%s\"' % model_pkl_path)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
