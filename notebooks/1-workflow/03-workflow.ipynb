{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz laden\n",
    "\n",
    "Quelle: [https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/safe-driver-prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadaten extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for column in df.columns:\n",
    "    # Defining the role\n",
    "    if column == 'target':\n",
    "        role = 'target'\n",
    "    elif column == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in column or column == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in column or column == 'id':\n",
    "        level = 'nominal'\n",
    "    elif df[column].dtype == np.dtype('float64'):\n",
    "        level = 'interval'\n",
    "    elif df[column].dtype == np.dtype('int64'):\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if column == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = df[column].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    column_dict = {\n",
    "        'column_name': column,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(column_dict)\n",
    "    \n",
    "df_meta = pd.DataFrame(data, columns=['column_name', 'role', 'level', 'keep', 'dtype'])\n",
    "df_meta.set_index('column_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorverarbeitung (Pre-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## Fehlende Werte\n",
    "\n",
    "* Kategorische Attribute\n",
    " * **ps_car_03_cat** & **ps_car_05_cat** enthalten mehr als 50% fehlende Werte ==> entfernen\n",
    " * Bei den anderen Attributen kann -1 als einzelne Kathegorie gewertet werden\n",
    "* **ps_reg_03** (continuous): Werte werden mit \"mean\" ersetzt\n",
    "* **ps_car_11** (ordinal): Werte werden mit \"most_frequent\" ersetzt\n",
    "* **ps_car_12** (continuous): Werte werden mit \"mean\" ersetzt\n",
    "* **ps_car_14** (continuous): Werte werden mit \"mean\" ersetzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "drop_list = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "df.drop(drop_list, inplace=True, axis=1)\n",
    "df_meta.loc[drop_list, 'keep'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "mean_imp = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "mode_imp = Imputer(missing_values=-1, strategy='most_frequent', axis=0)\n",
    "\n",
    "df['ps_reg_03'] = mean_imp.fit_transform(df[['ps_reg_03']])\n",
    "df['ps_car_12'] = mean_imp.fit_transform(df[['ps_car_12']])\n",
    "df['ps_car_14'] = mean_imp.fit_transform(df[['ps_car_14']])\n",
    "\n",
    "df['ps_car_11'] = mode_imp.fit_transform(df[['ps_car_11']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "[Resampling Strategies](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)\n",
    "\n",
    "Wie in der Übersicht gezeigt, ist der Anteil der Datensätze mit target = 1 weit geringer als target = 0. Dies kann zu einem Model führen, das eine hohe Genauigkeit aufweist, aber in der Praxis keine guten Resultate liefert. Zwei mögliche Strategien, um mit diesem Problem umzugehen, sind:\n",
    "\n",
    "* Oversampling der Datensätze mit target = 1\n",
    "* Undersampling der Datensätze mit target = 0\n",
    "\n",
    "Da wir ein größeres Trainingsset haben, können wir uns für Undersampling entscheiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwitt\\Anaconda3\\envs\\ds36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensätze mit target = 0 vor dem Undersampling: 573518\n",
      "Datensätze mit target = 0 nach dem Undersampling: 50619\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "desired_apriori = 0.30\n",
    "\n",
    "nb_0 = len(df.loc[df.target == 0].index)\n",
    "nb_1 = len(df.loc[df.target == 1].index)\n",
    "\n",
    "undersampling_rate = ((1 - desired_apriori) * nb_1) / (nb_0 * desired_apriori)\n",
    "undersampled_nb_0 = int(undersampling_rate * nb_0)\n",
    "\n",
    "df_X = df.drop('target', axis=1)\n",
    "df_y = df['target']\n",
    "\n",
    "cc = RandomUnderSampler(ratio={0: undersampled_nb_0})\n",
    "X_cc, y_cc = cc.fit_sample(df_X, df_y)\n",
    "\n",
    "df_X = pd.DataFrame(X_cc, columns=df_X.columns)\n",
    "df_y = pd.DataFrame(y_cc, columns=['target'])\n",
    "\n",
    "df = df_X.join(df_y)\n",
    "\n",
    "print('Datensätze mit target = 0 vor dem Undersampling: {}'.format(nb_0))\n",
    "print('Datensätze mit target = 0 nach dem Undersampling: {}'.format(len(df.loc[df.target == 0].index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy-Attribute erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "query = df_meta[(df_meta.level == 'nominal') & (df_meta.keep)].index\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for column in query.values:\n",
    "    if len(df[column].unique()) <= 2:\n",
    "        continue\n",
    "    df_bin = pd.DataFrame(lb.fit_transform(df[column].values), columns=['{}_{}'.format(column, c) for c in lb.classes_])\n",
    "    df = pd.concat([df, df_bin], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for org_column in query.values:\n",
    "    for lb_column in df.columns[df.columns.str.startswith(org_column+'_')]:\n",
    "        data.append({\n",
    "            'column_name': lb_column,\n",
    "            'role': 'input',\n",
    "            'level': 'binary',\n",
    "            'keep': True,\n",
    "            'dtype': df[lb_column].dtype\n",
    "        })\n",
    "    df_meta.loc[org_column, 'keep'] = False\n",
    "\n",
    "df_meta_tmp = pd.DataFrame(data, columns=['column_name', 'role', 'level', 'keep', 'dtype'])\n",
    "df_meta_tmp.set_index('column_name', inplace=True)\n",
    "\n",
    "df_meta = df_meta.append(df_meta_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Interaction\"-Attribute erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "query = df_meta[(df_meta.level == 'interval') & (df_meta.keep)].index\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "\n",
    "interactions = pd.DataFrame(poly.fit_transform(df[query]), columns=poly.get_feature_names(query))\n",
    "interactions.drop(query, axis=1, inplace=True)\n",
    "\n",
    "df = df.join(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for column in interactions.columns:\n",
    "    data.append({\n",
    "        'column_name': column,\n",
    "        'role': 'input',\n",
    "        'level': 'interval',\n",
    "        'keep': True,\n",
    "        'dtype': interactions[column].dtype\n",
    "    })\n",
    "\n",
    "df_meta_tmp = pd.DataFrame(data, columns=['column_name', 'role', 'level', 'keep', 'dtype'])\n",
    "df_meta_tmp.set_index('column_name', inplace=True)\n",
    "\n",
    "df_meta = df_meta.append(df_meta_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen von Attributen mit geringer oder keiner Varianz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=.01)\n",
    "selector.fit(df.drop(['id', 'target'], axis=1))\n",
    "\n",
    "f = np.vectorize(lambda x : not x)\n",
    "\n",
    "v = df.drop(['id', 'target'], axis=1).columns[f(selector.get_support())]\n",
    "print('{} variables have too low variance.'.format(len(v)))\n",
    "print('These variables are {}'.format(list(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "query = df_meta[((df_meta.level == 'interval') | (df_meta.level == 'ordinal')) & (df_meta.keep)].index\n",
    "\n",
    "df_tmp = df[query].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_tmp = pd.DataFrame(scaler.fit_transform(df_tmp), columns=df_tmp.columns)\n",
    "df.drop(df_tmp.columns, axis=1, inplace=True)\n",
    "df = df.join(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute auswählen mit Hilfe eines Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "query = df_meta[(df_meta.keep)].index\n",
    "\n",
    "# df_X = df.drop(['id', 'target'], axis=1)\n",
    "df_X = df[query].drop(['target'], axis=1)\n",
    "df_y = df['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(df_X, df_y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "df = pd.concat([df_X.loc[:, model.get_support()], df.loc[:, ['id', 'target']]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufteilung in Trainings- und Testdaten (Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "query = df_meta[(df_meta.keep)].index\n",
    "\n",
    "df_X = df[query].drop(['target'], axis=1)\n",
    "df_y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainieren des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "y_pred = cross_val_predict(clf, df_X, df_y, cv=StratifiedKFold(2), n_jobs=-1)\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(df_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " target = 0       0.71      0.71      0.71     50619\n",
      " target = 1       0.33      0.34      0.33     21694\n",
      "\n",
      "avg / total       0.60      0.60      0.60     72313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df_y, y_pred, target_names=['target = 0', 'target = 1']))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
